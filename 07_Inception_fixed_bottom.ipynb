{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import applications\n",
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Conv2D, Convolution2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "classes = 12\n",
    "batch_size=128\n",
    "train_total = 3783\n",
    "validation_total = 967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_inception = InceptionV3(include_top=False, weights = 'imagenet',input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = model_inception.get_layer('mixed10').output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=model_inception.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model_inception.layers:\n",
    "    layer.trainable= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.get_layer('batch_normalization_94').trainable= True\n",
    "model.get_layer('batch_normalization_86').trainable= True\n",
    "model.get_layer('conv2d_94').trainable= True\n",
    "model.get_layer('batch_normalization_93').trainable= True\n",
    "model.get_layer('batch_normalization_92').trainable= True\n",
    "model.get_layer('batch_normalization_89').trainable= True\n",
    "model.get_layer('batch_normalization_88').trainable= True\n",
    "model.get_layer('conv2d_86').trainable= True\n",
    "model.get_layer('conv2d_94').trainable= True\n",
    "model.get_layer('conv2d_93').trainable= True\n",
    "model.get_layer('conv2d_92').trainable= True\n",
    "model.get_layer('conv2d_89').trainable= True\n",
    "model.get_layer('conv2d_88').trainable= True\n",
    "model.get_layer('batch_normalization_91').trainable= True\n",
    "model.get_layer('batch_normalization_87').trainable= True\n",
    "model.get_layer('conv2d_91').trainable= True\n",
    "model.get_layer('conv2d_87').trainable= True\n",
    "model.get_layer('batch_normalization_90').trainable= True\n",
    "model.get_layer('conv2d_90').trainable= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   rotation_range = 20,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   fill_mode='reflect',\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    'train',\n",
    "                    target_size=(224,224),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical',\n",
    "                    shuffle=True\n",
    "                    )\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                        'validation',\n",
    "                        target_size=(224,224),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=RMSprop(lr=1e-7),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='inception_fixed_bottom_save_best.hdf5', verbose=1, save_best_only=True, save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 00000: val_loss improved from inf to 0.44380, saving model to inception_fixed_bottom_save_best.hdf5\n",
      "346s - loss: 0.6023 - acc: 0.7946 - val_loss: 0.4438 - val_acc: 0.8538\n",
      "Epoch 2/50\n",
      "Epoch 00001: val_loss did not improve\n",
      "201s - loss: 0.5979 - acc: 0.7952 - val_loss: 0.4597 - val_acc: 0.8570\n",
      "Epoch 3/50\n",
      "Epoch 00002: val_loss improved from 0.44380 to 0.44031, saving model to inception_fixed_bottom_save_best.hdf5\n",
      "235s - loss: 0.5922 - acc: 0.7971 - val_loss: 0.4403 - val_acc: 0.8538\n",
      "Epoch 4/50\n",
      "Epoch 00003: val_loss improved from 0.44031 to 0.42474, saving model to inception_fixed_bottom_save_best.hdf5\n",
      "217s - loss: 0.5810 - acc: 0.7922 - val_loss: 0.4247 - val_acc: 0.8581\n",
      "Epoch 5/50\n",
      "Epoch 00004: val_loss did not improve\n",
      "203s - loss: 0.5900 - acc: 0.7975 - val_loss: 0.4929 - val_acc: 0.8484\n",
      "Epoch 6/50\n",
      "Epoch 00005: val_loss improved from 0.42474 to 0.42202, saving model to inception_fixed_bottom_save_best.hdf5\n",
      "224s - loss: 0.5693 - acc: 0.8079 - val_loss: 0.4220 - val_acc: 0.8591\n",
      "Epoch 7/50\n",
      "Epoch 00006: val_loss did not improve\n",
      "208s - loss: 0.5833 - acc: 0.7990 - val_loss: 0.4246 - val_acc: 0.8581\n",
      "Epoch 8/50\n",
      "Epoch 00007: val_loss did not improve\n",
      "217s - loss: 0.5557 - acc: 0.8095 - val_loss: 0.4406 - val_acc: 0.8559\n",
      "Epoch 9/50\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch = int(np.ceil(train_total/batch_size)),\n",
    "                    epochs=50,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps= int(np.ceil(validation_total/batch_size)),\n",
    "                    verbose=2,\n",
    "                    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('inception_fixed_bottom_save_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(validation_generator, int(np.ceil(validation_total/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
